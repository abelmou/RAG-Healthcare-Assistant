{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1 : Data Generator for Model Training"
      ],
      "metadata": {
        "id": "3L_6h1vWFgZh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "alphabet = \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789 .,;:!?\\\"'()[]{}-\"\n",
        "char_to_index = {char: idx + 1 for idx, char in enumerate(alphabet)}\n",
        "\n",
        "def encode_text(text):\n",
        "    return [char_to_index[char] for char in text if char in char_to_index]\n",
        "\n",
        "def decode_text(encoded_text):\n",
        "    index_to_char = {v: k for k, v in char_to_index.items()}\n",
        "    return ''.join([index_to_char[idx] for idx in encoded_text if idx != 0])"
      ],
      "metadata": {
        "id": "pAhZo1l_DyAO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import Sequence\n",
        "\n",
        "class DataGenerator(Sequence):\n",
        "    def __init__(self, dataframe, batch_size, image_size, max_text_length):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            dataframe: DataFrame containing 'image_path' and 'text' columns.\n",
        "            batch_size: Number of samples per batch.\n",
        "            image_size: Tuple (height, width) for resizing images.\n",
        "            max_text_length: Maximum length of text labels (padded if shorter).\n",
        "        \"\"\"\n",
        "        self.dataframe = dataframe\n",
        "        self.batch_size = batch_size\n",
        "        self.image_size = image_size\n",
        "        self.max_text_length = max_text_length\n",
        "        self.indices = np.arange(len(self.dataframe))\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.dataframe) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        batch_indices = self.indices[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "        batch_data = self.dataframe.iloc[batch_indices]\n",
        "\n",
        "        images, labels, input_lengths, label_lengths = [], [], [], []\n",
        "\n",
        "        for _, row in batch_data.iterrows():\n",
        "\n",
        "            img = cv2.imread(row['image_path'], cv2.IMREAD_GRAYSCALE)\n",
        "            img = cv2.resize(img, (self.image_size[1], self.image_size[0])) / 255.0\n",
        "            img = np.expand_dims(img, axis=-1)\n",
        "\n",
        "            encoded_label = encode_text(row['label'])\n",
        "            label_length = len(encoded_label)\n",
        "\n",
        "            images.append(img)\n",
        "            labels.append(encoded_label)\n",
        "            input_lengths.append(self.image_size[1] // 4)\n",
        "            label_lengths.append(label_length)\n",
        "\n",
        "\n",
        "        labels_padded = np.zeros((len(labels), self.max_text_length), dtype=np.int32)\n",
        "        for i, label in enumerate(labels):\n",
        "            labels_padded[i, :len(label)] = label\n",
        "\n",
        "        return (\n",
        "            {\n",
        "                \"input_image\": np.array(images),\n",
        "                \"input_length\": np.array(input_lengths),\n",
        "                \"label\": labels_padded,\n",
        "                \"label_length\": np.array(label_lengths),\n",
        "            },\n",
        "            np.zeros(len(images)),\n",
        "        )\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        np.random.shuffle(self.indices)\n"
      ],
      "metadata": {
        "id": "savuLJ76Fni-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_csv = \"/content/drive/MyDrive/MoroccoAI-Hackathon-Project/data/IAM-Dataset/splits/train.csv\"\n",
        "val_csv = \"/content/drive/MyDrive/MoroccoAI-Hackathon-Project/data/IAM-Dataset/splits/val.csv\"\n",
        "\n",
        "batch_size = 32\n",
        "image_size = (128, 32)\n",
        "max_text_length = 100\n",
        "\n",
        "train_df = pd.read_csv(train_csv)\n",
        "val_df = pd.read_csv(val_csv)\n",
        "\n",
        "train_gen = DataGenerator(train_df, batch_size, image_size, max_text_length)\n",
        "val_gen = DataGenerator(val_df, batch_size, image_size, max_text_length)\n",
        "\n",
        "print(f\"Train generator batches: {len(train_gen)}\")\n",
        "print(f\"Validation generator batches: {len(val_gen)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymG3gF3gFuB2",
        "outputId": "d0628665-3b41-4a66-d0e1-bbee1a2e0dfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train generator batches: 263\n",
            "Validation generator batches: 33\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2 : Define and Build the Handwritten Text Recognition (HTR) Model\n"
      ],
      "metadata": {
        "id": "RAZMaTr0GwDo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Reshape, Dense, Bidirectional, LSTM, BatchNormalization, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "OxtAyVpGHjYu"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_htr_model(image_size, max_text_length, num_classes):\n",
        "    input_image = Input(shape=(*image_size, 1), name=\"input_image\")\n",
        "    labels = Input(shape=(max_text_length,), name=\"label\")\n",
        "    input_length = Input(shape=(1,), name=\"input_length\")\n",
        "    label_length = Input(shape=(1,), name=\"label_length\")\n",
        "\n",
        "    x = Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(input_image)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    x = Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    x = Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    new_shape = (image_size[0] // 8, (image_size[1] // 8) * 128)\n",
        "    x = Reshape(target_shape=new_shape)(x)\n",
        "\n",
        "    x = Bidirectional(LSTM(256, return_sequences=True))(x)\n",
        "    x = Dropout(0.25)(x)\n",
        "    x = Bidirectional(LSTM(256, return_sequences=True))(x)\n",
        "\n",
        "    x = Dense(num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "    def ctc_loss(args):\n",
        "        y_pred, labels, input_length, label_length = args\n",
        "        return tf.keras.backend.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
        "\n",
        "    output = tf.keras.layers.Lambda(ctc_loss, name=\"ctc_loss\")(\n",
        "        [x, labels, input_length, label_length]\n",
        "    )\n",
        "\n",
        "    model = Model(\n",
        "        inputs=[input_image, labels, input_length, label_length],\n",
        "        outputs=output,\n",
        "    )\n",
        "\n",
        "    model.compile(optimizer=Adam(learning_rate=1e-4),loss=ctc_loss)\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "unLZywwaIGta"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_size = (128, 32)\n",
        "max_text_length = 100\n",
        "num_classes = len(alphabet) + 1\n",
        "\n",
        "htr_model = build_htr_model(image_size, max_text_length, num_classes)\n",
        "htr_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJ8pkwNzIJg-",
        "outputId": "430b87de-f254-44b8-d4ec-e8a0a82512f1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_image (InputLayer)    [(None, 128, 32, 1)]         0         []                            \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)           (None, 128, 32, 32)          320       ['input_image[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPoolin  (None, 64, 16, 32)           0         ['conv2d_3[0][0]']            \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " batch_normalization_3 (Bat  (None, 64, 16, 32)           128       ['max_pooling2d_3[0][0]']     \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)           (None, 64, 16, 64)           18496     ['batch_normalization_3[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " max_pooling2d_4 (MaxPoolin  (None, 32, 8, 64)            0         ['conv2d_4[0][0]']            \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " batch_normalization_4 (Bat  (None, 32, 8, 64)            256       ['max_pooling2d_4[0][0]']     \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)           (None, 32, 8, 128)           73856     ['batch_normalization_4[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " max_pooling2d_5 (MaxPoolin  (None, 16, 4, 128)           0         ['conv2d_5[0][0]']            \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " batch_normalization_5 (Bat  (None, 16, 4, 128)           512       ['max_pooling2d_5[0][0]']     \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " reshape_1 (Reshape)         (None, 16, 512)              0         ['batch_normalization_5[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " bidirectional_2 (Bidirecti  (None, 16, 512)              1574912   ['reshape_1[0][0]']           \n",
            " onal)                                                                                            \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)         (None, 16, 512)              0         ['bidirectional_2[0][0]']     \n",
            "                                                                                                  \n",
            " bidirectional_3 (Bidirecti  (None, 16, 512)              1574912   ['dropout_1[0][0]']           \n",
            " onal)                                                                                            \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 16, 79)               40527     ['bidirectional_3[0][0]']     \n",
            "                                                                                                  \n",
            " label (InputLayer)          [(None, 100)]                0         []                            \n",
            "                                                                                                  \n",
            " input_length (InputLayer)   [(None, 1)]                  0         []                            \n",
            "                                                                                                  \n",
            " label_length (InputLayer)   [(None, 1)]                  0         []                            \n",
            "                                                                                                  \n",
            " ctc_loss (Lambda)           (None, 1)                    0         ['dense_1[0][0]',             \n",
            "                                                                     'label[0][0]',               \n",
            "                                                                     'input_length[0][0]',        \n",
            "                                                                     'label_length[0][0]']        \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 3283919 (12.53 MB)\n",
            "Trainable params: 3283471 (12.53 MB)\n",
            "Non-trainable params: 448 (1.75 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3 : Training the Handwritten Text Recognition Model"
      ],
      "metadata": {
        "id": "UkW_5plQISAP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = DataGenerator(\n",
        "    train_gen,\n",
        "    batch_size=batch_size,\n",
        "    image_size=image_size,\n",
        "    max_text_length=max_text_length\n",
        ")\n",
        "\n",
        "val_generator = DataGenerator(\n",
        "    val_gen,\n",
        "    batch_size=batch_size,\n",
        "    image_size=image_size,\n",
        "    max_text_length=max_text_length\n",
        ")"
      ],
      "metadata": {
        "id": "1MvnuIeiJZgn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "steps_per_epoch = len(train_gen)\n",
        "validation_steps = len(val_gen)\n",
        "\n",
        "history = htr_model.fit(\n",
        "    train_gen,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    validation_data=val_gen,\n",
        "    validation_steps=validation_steps,\n",
        "    epochs=30\n",
        ")"
      ],
      "metadata": {
        "id": "wQvsDeowQivf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "htr_model.save('/content/drive/MyDrive/IAM-Dataset/handwritten_text_recognition_model.h5')\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['loss'], label='Training loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.title('Training vs Validation Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Gzf1s630SJf7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}